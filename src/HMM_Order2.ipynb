{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from numpy import array, ones, zeros, multiply\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "train10=pickle.load( open( \"../data/train10.pkl\", \"rb\" ))\n",
    "test10=pickle.load( open( \"../data/test10.pkl\", \"rb\" ))\n",
    "train20=pickle.load( open( \"../data/train20.pkl\", \"rb\" ))\n",
    "test20=pickle.load( open( \"../data/test20.pkl\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HMM:\n",
    "        def __init__(self, state_list, observation_list,\n",
    "                 transition_proba = None,\n",
    "                 observation_proba = None,\n",
    "                 initial_state_proba = None, smoothing_obs = 0.01):\n",
    "          \n",
    "            print \"HMM creating with: \"\n",
    "            self.N = len(state_list)       # number of states\n",
    "            self.M = len(observation_list) # number of possible emissions\n",
    "            print str(self.N)+\" states\"\n",
    "            print str(self.M)+\" observations\"\n",
    "            \n",
    "            self.omega_Y = state_list\n",
    "            self.omega_Y.append(\"*\")\n",
    "            self.omega_X = observation_list\n",
    "            \n",
    "            if transition_proba is None:\n",
    "                self.transition_proba = zeros( (self.N+1, self.N+1, self.N), float) \n",
    "            else:\n",
    "                self.transition_proba=transition_proba\n",
    "            if observation_proba is None:\n",
    "                self.observation_proba = zeros( (self.M, self.N), float) \n",
    "            else:\n",
    "                self.observation_proba=observation_proba\n",
    "            \"\"\"if initial_state_proba is None:\n",
    "                self.initial_state_proba = zeros( (self.N,), float ) \n",
    "            else:\n",
    "                self.initial_state_proba=initial_state_proba\n",
    "            \"\"\"\n",
    "            self.make_indexes() # build indexes, i.e the mapping between token and int\n",
    "            self.smoothing_obs = smoothing_obs \n",
    "            \n",
    "        def make_indexes(self):\n",
    "            \"\"\"Creates the reverse table that maps states/observations names\n",
    "            to their index in the probabilities array\"\"\"\n",
    "            self.Y_index = {}\n",
    "            for i in range(self.N+1):\n",
    "                self.Y_index[self.omega_Y[i]] = i\n",
    "                \n",
    "            self.X_index = {}\n",
    "            for i in range(self.M):\n",
    "                self.X_index[self.omega_X[i]] = i\n",
    "      \n",
    "        def get_observationIndices( self, observations ):\n",
    "            \"\"\"return observation indices, i.e \n",
    "            return [self.O_index[o] for o in observations]\n",
    "            and deals with OOVs TODO \n",
    "            \"\"\"\n",
    "            indices = zeros( len(observations), int )\n",
    "            k = 0\n",
    "            for o in observations:\n",
    "                if o in self.X_index:\n",
    "                    indices[k] = self.X_index[o]\n",
    "                k += 1\n",
    "            return indices\n",
    "\n",
    "    \n",
    "        def data2indices(self, sent): \n",
    "            \"\"\"From a word of the corpus: \n",
    "            - extract the letter and coorection \n",
    "            - returns two list of indices, one for each\n",
    "            -> (letterid, correctionid)\n",
    "            \"\"\"\n",
    "            letterids = list()\n",
    "            correctionids  = list()\n",
    "            for couple in sent:\n",
    "                ltr = couple[0]\n",
    "                crt = couple[1]\n",
    "                letterids.append(self.X_index[ltr])\n",
    "                correctionids.append(self.Y_index[crt])\n",
    "            return letterids,correctionids\n",
    "            \n",
    "        def observation_estimation(self, pair_counts):\n",
    "\n",
    "            for pair in pair_counts:\n",
    "                letter=pair[0]\n",
    "                correction=pair[1]\n",
    "                count=pair_counts[pair]\n",
    "                \n",
    "                if letter in self.X_index:\n",
    "                    k=self.X_index[letter]\n",
    "                i=self.Y_index[correction]\n",
    "                self.observation_proba[k,i]=count\n",
    "            self.observation_proba=self.observation_proba+self.smoothing_obs\n",
    "            self.observation_proba=self.observation_proba/self.observation_proba.sum(axis=0).reshape(1, self.N)\n",
    "                        \n",
    "        def transition_estimation(self, c_bitag, c_tritag):\n",
    "            \n",
    "            for tritag in c_tritag:\n",
    "                #getting indices\n",
    "                y_2=self.Y_index[tritag[0]]\n",
    "                y_1=self.Y_index[tritag[1]]\n",
    "                y=self.Y_index[tritag[2]]\n",
    "                bigram=(tritag[0],tritag[1])       \n",
    "                self.transition_proba[y_2,y_1,y]=float(c_tritag[tritag])/float(c_bitag[bigram])               \n",
    "   \n",
    "        def init_estimation(self, c_inits, c_inits_bitag):\n",
    "            somme=float(sum(c_inits.values()))\n",
    "            for correction in c_inits:\n",
    "                i=self.Y_index[correction]\n",
    "                j=self.Y_index[\"*\"]\n",
    "                self.transition_proba[j,j,i]=float(c_inits[correction])/somme\n",
    "                \n",
    "            for pair in c_inits_bitag:\n",
    "                y_1=self.Y_index[pair[0]]\n",
    "                y=self.Y_index[pair[1]]\n",
    "                j=self.Y_index[\"*\"]\n",
    "                self.transition_proba[j,y_1,y]=float(c_inits_bitag[pair])/float(c_inits[pair[0]])\n",
    "                \n",
    "            \n",
    "\n",
    "        def supervised_training(self, pair_counts, c_bitag, c_tritag ,c_inits, c_inits_bitag):\n",
    "            \"\"\" Train the HMM's parameters. This function wraps everything\"\"\"\n",
    "            self.observation_estimation(pair_counts)\n",
    "            self.transition_estimation(c_bitag, c_tritag)\n",
    "            self.init_estimation(c_inits, c_inits_bitag)\n",
    "        \n",
    "        def get_possible_corrections(self,k):\n",
    "            if k == -1:\n",
    "                return set(['*'])\n",
    "            if k == 0:\n",
    "                return set(['*'])\n",
    "            else:\n",
    "                return self.omega_Y[0:26]\n",
    "\n",
    "        def get_letter(self,word,k):\n",
    "            if k < 0:\n",
    "                return '*'\n",
    "            else:\n",
    "                return word[k]\n",
    "\n",
    "        def viterbi(self,word):\n",
    "            V = {}\n",
    "            path = {}\n",
    "            # init\n",
    "            V[0,'*','*'] = 1\n",
    "            path['*','*'] = []\n",
    "            \n",
    "            for k in range(1,len(word)+1):\n",
    "                temp_path = {}\n",
    "                letter = self.X_index[self.get_letter(word,k-1)]\n",
    "                \n",
    "                for u in self.get_possible_corrections(k-1):\n",
    "                    \n",
    "                    for v in self.get_possible_corrections(k):\n",
    "\n",
    "                        i_u=self.Y_index[u]\n",
    "                        i_v=self.Y_index[v]\n",
    "                        \n",
    "                        V[k,u,v],backpointer = max([(V[k-1,w,u] * self.transition_proba[self.Y_index[w],i_u,i_v] * self.observation_proba[letter,i_v],w) for w in self.get_possible_corrections(k-2)])                       \n",
    "                        \n",
    "                        temp_path[u,v] = path[backpointer,u] + [v]                        \n",
    "                path = temp_path\n",
    "                \n",
    "            prob,maxu,maxv= max([(V[k,u,v],u,v) for u in self.omega_Y[0:26] for v in self.omega_Y[0:26]])\n",
    "                \n",
    "            \n",
    "            return prob, path[maxu,maxv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_counts(corpus):\n",
    "    \"\"\" \n",
    "    Build different count tables to train a HMM. Each count table is a dictionnary. \n",
    "    Returns: \n",
    "    * c_letter: letter counts\n",
    "    * c_correction: correction counts\n",
    "    * c_pairs: count of pairs (letter,correction)\n",
    "    \n",
    "    * c_bitag: count of tag bigram \n",
    "    * c_tritag: count of tag trigram \n",
    "    * c_inits: count of tag found in the first position\n",
    "    \n",
    "    \"\"\"\n",
    "    c_letter = dict()\n",
    "    c_correction = dict()\n",
    "    c_pairs= dict()\n",
    "    c_bitag = dict()\n",
    "    c_tritag = dict()\n",
    "    c_inits = dict()\n",
    "    c_inits_bitag = dict()\n",
    "    \n",
    "    for word in corpus:\n",
    "        for i in range(len(word)):\n",
    "            couple= word[i]\n",
    "            letter = couple[0]\n",
    "            correction = couple[1]\n",
    "            #Counting letter \n",
    "            if letter in c_letter:\n",
    "                c_letter[letter] +=1\n",
    "            else:\n",
    "                c_letter[letter] =1  \n",
    "            #Counting correction\n",
    "            if correction in c_correction:\n",
    "                c_correction[correction] +=1\n",
    "            else:\n",
    "                c_correction[correction] =1\n",
    "            #Counting par(letter, correction)\n",
    "            if couple in c_pairs:\n",
    "                c_pairs[couple] +=1\n",
    "            else :\n",
    "                c_pairs[couple] =1\n",
    "            #Counting bitag(corr_i, corr_(i+1))\n",
    "            if i > 0 and i < len(word)-1:\n",
    "                bitag = (word[i-1][1], correction)\n",
    "                if bitag in c_bitag:\n",
    "                    c_bitag[bitag] += 1\n",
    "                else:\n",
    "                    c_bitag[bitag] =1\n",
    "                    \n",
    "            #Counting tritag\n",
    "            if i > 1:\n",
    "                tritag = (word[i-2][1],word[i-1][1], correction)\n",
    "                if tritag in c_tritag :\n",
    "                    c_tritag[tritag] +=1\n",
    "                else :\n",
    "                    c_tritag[tritag] =1\n",
    "                    \n",
    "            if i == 0 and len(word)>1:\n",
    "                if correction in c_inits:\n",
    "                    c_inits[correction] +=1\n",
    "                else :\n",
    "                    c_inits[correction] =1\n",
    "                bg_first=(correction,word[i+1][1])\n",
    "                \n",
    "                if bg_first in c_inits_bitag:\n",
    "                    c_inits_bitag[bg_first]+=1\n",
    "                else:\n",
    "                    c_inits_bitag[bg_first]=1\n",
    "                    \n",
    "    return c_letter, c_correction, c_pairs, c_bitag, c_tritag, c_inits, c_inits_bitag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_letter, c_correction, c_pairs, c_bitag, c_tritag, c_inits, c_inits_bitag=make_counts(train20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM creating with: \n",
      "26 states\n",
      "26 observations\n"
     ]
    }
   ],
   "source": [
    "hmm = HMM(state_list=c_correction.keys(), observation_list=c_letter.keys(),\n",
    "                 transition_proba = None,\n",
    "                 observation_proba = None,\n",
    "                 initial_state_proba = None)\n",
    "hmm.supervised_training( c_pairs, c_bitag, c_tritag ,c_inits, c_inits_bitag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wrong_words=[]\n",
    "true_words=[] #denotes all underlying hidden states\n",
    "for sent in test20:\n",
    "    data = np.asarray(sent)\n",
    "    obs,states = np.hsplit(data,2)\n",
    "    wrong_words.append(obs.tostring())\n",
    "    true_words.append(list(states.tostring()))\n",
    "wrong_words = np.array(wrong_words)\n",
    "true_words = np.array(true_words)   #These are the true lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correction_words=[]\n",
    "for word in wrong_words:\n",
    "    if(len(word)>1):\n",
    "        p,v=hmm.viterbi(word)\n",
    "    else:\n",
    "        v=list(word)\n",
    "    correction_words.append(v)\n",
    "correction_words=np.array(correction_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_error(correction_words,true_words):\n",
    "    \"\"\"Compares the corrections and true_vals\"\"\"\n",
    "    error=0\n",
    "    total=0\n",
    "    for f, b in zip(correction_words, true_words):\n",
    "        if cmp(f,b)!=0:\n",
    "            for i in range(len(f)):\n",
    "                if f[i]!=b[i]:\n",
    "                    error+=1\n",
    "        total+=len(f)\n",
    "\n",
    "    return float(error)/float(total)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print compute_error(correction_words,true_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
