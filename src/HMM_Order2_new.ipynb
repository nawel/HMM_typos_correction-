{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from numpy import array, ones, zeros, multiply\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "data=pickle.load( open( \"D:/GitHub/HMM_typos_correction-/data/train10.pkl\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HMM:\n",
    "        def __init__(self, state_list, observation_list,\n",
    "                 transition_proba = None,\n",
    "                 observation_proba = None,\n",
    "                 initial_state_proba = None, smoothing_obs = 0.01):\n",
    "          \n",
    "            print \"HMM creating with: \"\n",
    "            self.N = len(state_list)       # number of states\n",
    "            self.M = len(observation_list) # number of possible emissions\n",
    "            print str(self.N)+\" states\"\n",
    "            print str(self.M)+\" observations\"\n",
    "            \n",
    "            self.omega_Y = state_list\n",
    "            self.omega_Y.append(\"*\")\n",
    "            self.omega_X = observation_list\n",
    "            \n",
    "            if transition_proba is None:\n",
    "                self.transition_proba = zeros( (self.N+1, self.N+1, self.N), float) \n",
    "            else:\n",
    "                self.transition_proba=transition_proba\n",
    "            if observation_proba is None:\n",
    "                self.observation_proba = zeros( (self.M, self.N), float) \n",
    "            else:\n",
    "                self.observation_proba=observation_proba\n",
    "            \"\"\"if initial_state_proba is None:\n",
    "                self.initial_state_proba = zeros( (self.N,), float ) \n",
    "            else:\n",
    "                self.initial_state_proba=initial_state_proba\n",
    "            \"\"\"\n",
    "            self.make_indexes() # build indexes, i.e the mapping between token and int\n",
    "            self.smoothing_obs = smoothing_obs \n",
    "            \n",
    "        def make_indexes(self):\n",
    "            \"\"\"Creates the reverse table that maps states/observations names\n",
    "            to their index in the probabilities array\"\"\"\n",
    "            self.Y_index = {}\n",
    "            for i in range(self.N+1):\n",
    "                self.Y_index[self.omega_Y[i]] = i\n",
    "                \n",
    "            self.X_index = {}\n",
    "            for i in range(self.M):\n",
    "                self.X_index[self.omega_X[i]] = i\n",
    "      \n",
    "        def get_observationIndices( self, observations ):\n",
    "            \"\"\"return observation indices, i.e \n",
    "            return [self.O_index[o] for o in observations]\n",
    "            and deals with OOVs\n",
    "            \"\"\"\n",
    "            indices = zeros( len(observations), int )\n",
    "            k = 0\n",
    "            for o in observations:\n",
    "                if o in self.X_index:\n",
    "                    indices[k] = self.X_index[o]\n",
    "                k += 1\n",
    "            return indices\n",
    "\n",
    "    \n",
    "        def data2indices(self, sent): \n",
    "            \"\"\"From a word of the corpus: \n",
    "            - extract the letter and coorection \n",
    "            - returns two list of indices, one for each\n",
    "            -> (letterid, correctionid)\n",
    "            \"\"\"\n",
    "            letterids = list()\n",
    "            correctionids  = list()\n",
    "            for couple in sent:\n",
    "                ltr = couple[0]\n",
    "                crt = couple[1]\n",
    "                letterids.append(self.X_index[ltr])\n",
    "                correctionids.append(self.Y_index[crt])\n",
    "            return letterids,correctionids\n",
    "            \n",
    "        def observation_estimation(self, pair_counts):\n",
    "\n",
    "            for pair in pair_counts:\n",
    "                letter=pair[0]\n",
    "                correction=pair[1]\n",
    "                count=pair_counts[pair]\n",
    "                \n",
    "                if letter in self.X_index:\n",
    "                    k=self.X_index[letter]\n",
    "                i=self.Y_index[correction]\n",
    "                self.observation_proba[k,i]=count\n",
    "            self.observation_proba=self.observation_proba+self.smoothing_obs\n",
    "            self.observation_proba=self.observation_proba/self.observation_proba.sum(axis=0).reshape(1, self.N)\n",
    "                        \n",
    "        def transition_estimation(self, c_bitag, c_tritag):\n",
    "            \n",
    "            for tritag in c_tritag:\n",
    "                #getting indices\n",
    "                y_2=self.Y_index[tritag[0]]\n",
    "                y_1=self.Y_index[tritag[1]]\n",
    "                y=self.Y_index[tritag[2]]\n",
    "                bigram=(tritag[0],tritag[1])       \n",
    "                self.transition_proba[y_2,y_1,y]=float(c_tritag[tritag])/float(c_bitag[bigram])               \n",
    "   \n",
    "        def init_estimation(self, c_inits, c_inits_bitag):\n",
    "            somme=float(sum(c_inits.values()))\n",
    "            for correction in c_inits:\n",
    "                i=self.Y_index[correction]\n",
    "                j=self.Y_index[\"*\"]\n",
    "                self.transition_proba[j,j,i]=float(c_inits[correction])/somme\n",
    "                \n",
    "            for pair in c_inits_bitag:\n",
    "                y_1=self.Y_index[pair[0]]\n",
    "                y=self.Y_index[pair[1]]\n",
    "                j=self.Y_index[\"*\"]\n",
    "                self.transition_proba[j,y_1,y]=float(c_inits_bitag[pair])/float(c_inits[pair[0]])\n",
    "                \n",
    "            \n",
    "\n",
    "        def supervised_training(self, pair_counts, c_bitag, c_tritag ,c_inits, c_inits_bitag):\n",
    "            \"\"\" Train the HMM's parameters. This function wraps everything\"\"\"\n",
    "            self.observation_estimation(pair_counts)\n",
    "            self.transition_estimation(c_bitag, c_tritag)\n",
    "            self.init_estimation(c_inits, c_inits_bitag)\n",
    "        \n",
    "        def get_possible_corrections(self,k):\n",
    "            if k == -1:\n",
    "                return set(['*'])\n",
    "            if k == 0:\n",
    "                return set(['*'])\n",
    "            else:\n",
    "                return self.omega_Y[0:26]\n",
    "\n",
    "        def get_letter(self,word,k):\n",
    "            if k < 0:\n",
    "                return '*'\n",
    "            else:\n",
    "                return word[k]\n",
    "\n",
    "        def viterbi(self,word):\n",
    "            V = {}\n",
    "            path = {}\n",
    "            # init\n",
    "            V[0,'*','*'] = 1\n",
    "            path['*','*'] = []\n",
    "            \n",
    "            for k in range(1,len(word)+1):\n",
    "                temp_path = {}\n",
    "                letter = self.X_index[self.get_letter(word,k-1)]\n",
    "                \n",
    "                for u in self.get_possible_corrections(k-1):\n",
    "                    \n",
    "                    for v in self.get_possible_corrections(k):\n",
    "\n",
    "                        i_u=self.Y_index[u]\n",
    "                        i_v=self.Y_index[v]\n",
    "                        \n",
    "                        V[k,u,v],backpointer = max([(V[k-1,w,u] * self.transition_proba[self.Y_index[w],i_u,i_v] * self.observation_proba[letter,i_v],w) for w in self.get_possible_corrections(k-2)])                       \n",
    "                        \n",
    "                        temp_path[u,v] = path[backpointer,u] + [v]                        \n",
    "                path = temp_path\n",
    "                \n",
    "            prob,maxu,maxv= max([(V[k,u,v],u,v) for u in self.omega_Y[0:26] for v in self.omega_Y[0:26]])\n",
    "                \n",
    "            \n",
    "            return path[maxu,maxv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_counts(corpus):\n",
    "    \"\"\" \n",
    "    Build different count tables to train a HMM. Each count table is a dictionnary. \n",
    "    Returns: \n",
    "    * c_letter: letter counts\n",
    "    * c_correction: correction counts\n",
    "    * c_pairs: count of pairs (letter,correction)\n",
    "    \n",
    "    * c_bitag: count of tag bigram \n",
    "    * c_tritag: count of tag trigram \n",
    "    * c_inits: count of tag found in the first position\n",
    "    \n",
    "    \"\"\"\n",
    "    c_letter = dict()\n",
    "    c_correction = dict()\n",
    "    c_pairs= dict()\n",
    "    c_bitag = dict()\n",
    "    c_tritag = dict()\n",
    "    c_inits = dict()\n",
    "    c_inits_bitag = dict()\n",
    "    \n",
    "    for word in corpus:\n",
    "        for i in range(len(word)):\n",
    "            couple= word[i]\n",
    "            letter = couple[0]\n",
    "            correction = couple[1]\n",
    "            #Counting letter \n",
    "            if letter in c_letter:\n",
    "                c_letter[letter] +=1\n",
    "            else:\n",
    "                c_letter[letter] =1  \n",
    "            #Counting correction\n",
    "            if correction in c_correction:\n",
    "                c_correction[correction] +=1\n",
    "            else:\n",
    "                c_correction[correction] =1\n",
    "            #Counting par(letter, correction)\n",
    "            if couple in c_pairs:\n",
    "                c_pairs[couple] +=1\n",
    "            else :\n",
    "                c_pairs[couple] =1\n",
    "            #Counting bitag(corr_i, corr_(i+1))\n",
    "            if i > 0 and i < len(word)-1:\n",
    "                bitag = (word[i-1][1], correction)\n",
    "                if bitag in c_bitag:\n",
    "                    c_bitag[bitag] += 1\n",
    "                else:\n",
    "                    c_bitag[bitag] =1\n",
    "                    \n",
    "            #Counting tritag\n",
    "            if i > 1:\n",
    "                tritag = (word[i-2][1],word[i-1][1], correction)\n",
    "                if tritag in c_tritag :\n",
    "                    c_tritag[tritag] +=1\n",
    "                else :\n",
    "                    c_tritag[tritag] =1\n",
    "                    \n",
    "            if i == 0 and len(word)>1:\n",
    "                if correction in c_inits:\n",
    "                    c_inits[correction] +=1\n",
    "                else :\n",
    "                    c_inits[correction] =1\n",
    "                bg_first=(correction,word[i+1][1])\n",
    "                \n",
    "                if bg_first in c_inits_bitag:\n",
    "                    c_inits_bitag[bg_first]+=1\n",
    "                else:\n",
    "                    c_inits_bitag[bg_first]=1\n",
    "                    \n",
    "    return c_letter, c_correction, c_pairs, c_bitag, c_tritag, c_inits, c_inits_bitag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_letter, c_correction, c_pairs, c_bitag, c_tritag, c_inits, c_inits_bitag=make_counts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM creating with: \n",
      "26 states\n",
      "26 observations\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "hmm = HMM(state_list=c_correction.keys(), observation_list=c_letter.keys(),\n",
    "                 transition_proba = None,\n",
    "                 observation_proba = None,\n",
    "                 initial_state_proba = None)\n",
    "hmm.supervised_training( c_pairs, c_bitag, c_tritag ,c_inits, c_inits_bitag)\n",
    "word=\"acvount\"\n",
    "v=hmm.viterbi(word)\n",
    "print v[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data is assumed to comes in chains of observation, so recovering each chain of observation\n",
    "Xd=[]\n",
    "allq=[] #denotes all underlying hidden states\n",
    "test=pickle.load( open( \"D:/GitHub/HMM_typos_correction-/data/test10.pkl\", \"rb\" ))\n",
    "for sent in test:\n",
    "    data = np.asarray(sent)\n",
    "    obs,states = np.hsplit(data,2)\n",
    "    Xd.append(obs)\n",
    "    allq.append(states)\n",
    "del test\n",
    "Xd = np.array(Xd)\n",
    "allq = np.array(allq)   #These are the true lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_states(Xd,hmm):\n",
    "\t# 'allq' stands for current estimated hidden_states\n",
    "\n",
    "\tprobs=[]\n",
    "\tstates=[]\t#new hidden-states given observations Xc\n",
    "\tfor x in Xd:\n",
    "\t\tst = str()\n",
    "        \tfor letter in x:\n",
    "            \t\tst+=letter[0]\n",
    "\t\tprob = None\n",
    "\t        if len(st)>1:\n",
    "        \t    state = hmm.viterbi(st)\t#finding states and most likely path given these models(i.e fixed Pi,A,B)\n",
    "        \telse:\n",
    "                \tstate = [st]\n",
    "        \tstates.append(state)\n",
    "        \tprobs.append(prob)\n",
    "\n",
    "\treturn probs,states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-dca6082625bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mallq_est\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mfind_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhmm\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m# Running the Viterbi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-d7ed8332e305>\u001b[0m in \u001b[0;36mfind_states\u001b[1;34m(Xd, hmm)\u001b[0m\n\u001b[0;32m     10\u001b[0m                 \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m                     \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhmm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviterbi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;31m#finding states and most likely path given these models(i.e fixed Pi,A,B)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-50cbfab76e81>\u001b[0m in \u001b[0;36mviterbi\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    148\u001b[0m                         \u001b[0mi_v\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m                         \u001b[0mV\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbackpointer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransition_proba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi_u\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi_v\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_proba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mletter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi_v\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_possible_corrections\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m                         \u001b[0mtemp_path\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbackpointer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "probs,allq_est =  find_states(Xd,hmm)    # Running the Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_error(corrections,true_vals):\n",
    "    \"\"\"Compares the corrections and true_vals\"\"\"\n",
    "    error=0\n",
    "    total=0\n",
    "    for f, b in zip(corrections, true_vals):\n",
    "        for i in range(len(f)):\n",
    "            if f[i][0]!=b[i]:\n",
    "                error+=1\n",
    "    total+=len(f)\n",
    "\n",
    "    return float(error)/float(total)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
